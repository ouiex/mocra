# Mocra Documentation Overview

This directory has been consolidated and simplified. **Architecture, data structures, processing flows, distributed deployment, and configuration** are centralized on this page. Other historical documents are preserved as references or merged into this overview.

---

## 1. System Overview

Mocra is a **distributed, event-driven crawling and data collection framework**. Its core design principles are:
- **Stateless workers** + **shared external storage** (Redis/Postgres)
- **Unified message contracts** (Task/Request/Response/ParserTask/Data)
- **Pluggable modules and middleware** (download, parse, store)
- **Distributed scheduling and leader election** (Cron + Leader Election)

Core components:
- **Engine**: scheduling and pipeline execution
- **Queue**: message bus (Redis Streams / Kafka)
- **Downloader**: network fetching with cache/rate-limit support
- **Common**: configuration, state, models, interface contracts
- **Sync**: distributed consistency and leader election
- **Cacheable**: two-level cache (local + Redis)

---

## 2. Core Data Structures (DTO)

> See `src/common/model/*` for details.

### 2.1 TaskModel
**Purpose**: top-level task descriptor (account/platform/module/priority/runtime instance).
- Main fields:
	- `account` / `platform` / `module`
	- `priority` (high/normal/low)
	- `run_id` (runtime instance)
	- `metadata` (task context)
- Source: API/Cron

### 2.2 Request
**Purpose**: concrete request unit (HTTP/WebSocket).
- Main fields:
	- `url`, `method`, `headers`, `cookies`
	- `context` (ExecutionMark)
	- `run_id`, `priority`, `request_hash`
- Generated by `Module.generate()` or parser output

### 2.3 Response
**Purpose**: download result.
- Main fields:
	- `status_code`, `content`, `headers`
	- `context`, `run_id`, `request_hash`
	- `storage_path` (for large payload offloading)
- Produced by `Downloader`

### 2.4 ParserTask
**Purpose**: follow-up task and step-state artifact produced during parsing.
- Main fields: `metadata`, `context`, `prefix_request`

### 2.6 ParserData
**Purpose**: parser output envelope; can carry extracted data and next-step control signals together.
- Main fields:
	- `data: Vec<Data>`
	- `parser_task: Vec<ParserTaskModel>`
	- `error_task: Option<ErrorTaskModel>`
	- `stop: Option<bool>`

**v0.1.1 change**:
- `parser_task` was migrated from `Option<ParserTaskModel>` to `Vec<ParserTaskModel>`.
- A parser node can now produce multiple downstream parser tasks in one parse cycle.
- `with_task(...)` is backward-compatible (it now appends into `parser_task`).
- Downstream should use vector semantics (e.g., `drain(..)` / `is_empty()`), not `take()` / `is_some()`.

### 2.5 Data
**Purpose**: business data extracted by parsers.
- Main fields: `data` (Json/DataFrame/File, etc.), `meta`, `data_middleware`

---

## 3. Processing Flow (Pipeline)

```text
TaskModel -> TaskProcessor -> Request
Request   -> DownloadProcessor -> Response
Response  -> ParserProcessor -> (Data / Request / ParserTask)
ParserTask -> ParserTaskProcessor -> Request / Data
```

Flow highlights:
- **DownloadMiddleware**: request signing, proxying, encryption, authentication
- **DataMiddleware**: cleansing, validation, deduplication, format conversion
- **DataStoreMiddleware**: persistence (PG/OSS/ES)

**v0.1.2 middleware contract update**:
- Middleware traits `DownloadMiddleware` / `DataMiddleware` / `DataStoreMiddleware` use `&mut self` in hook methods.
- `DataStoreMiddleware` adds lifecycle hooks:
	- `before_store(&mut self, _config: &Option<ModuleConfig>) -> Result<()>`
	- `after_store(&mut self, _config: &Option<ModuleConfig>) -> Result<()>`
- Store stage call order is `before_store -> store_data -> after_store`.
- If `before_store` returns `Err`, store execution short-circuits and enters existing error handling/retry path.

---

## 4. Distributed Deployment

### 4.1 Roles
- **Worker**: runs Engine (core processors + queue consumers)
- **Scheduler Leader**: distributed Cron scheduler; only the leader triggers tasks
- **Control Plane (optional)**: management API and monitoring

### 4.2 Infrastructure
- **Redis**: queue (Stream), cache, locks, rate limiting, node registry, deduplication
- **Postgres**: task configurations, logs, business data
- **Kafka (optional)**: alternative for high-throughput messaging

### 4.3 Scaling
- **Horizontal scaling**: increase worker count
- **Queue sharding**: Redis Streams sharding or multi-queue topology
- **Read/write separation**: DB/Redis primary-replica or clustered setup

---

## 5. Configuration

Detailed configuration reference: `docs/configuration.md`

**Database and Redis conventions**:
- Use `db.url` to simplify database settings.
- Redis uses unified `redis_host/redis_port/redis_db` fields.

**Main config blocks**:
- `[db]`: database connection (`url`/`pool_size`)
- `[cache.redis]`: cache Redis
- `[channel_config.redis]`: queue Redis (Stream)
- `[download_config]`: downloader concurrency, timeout, rate limit
- `[crawler]`: global task fault tolerance and concurrency settings

**Runtime mode auto-detection**:
- `runtime.mode` is no longer used.
- If `[cache.redis]` exists, Engine runs in distributed mode; otherwise single-node mode.

Example (excerpt):
```toml
[db]
url = "postgres://user:password@localhost:5432/crawler"
pool_size = 10

[channel_config.redis]
redis_host = "127.0.0.1"
redis_port = 6379
redis_db = 0
pool_size = 100
shards = 8
listener_count = 8
```

Test configuration samples:
- `tests/config.test.toml`
- `tests/config.mock.toml`
- `tests/config.mock.pure.toml`
- `tests/config.mock.pure.engine.toml`
- `tests/config.prod_like.toml`

---

## 6. Runtime and Deployment Recommendations

- Enable Redis persistence (**AOF/RDB**).
- Configure Postgres connection pools and indexes properly.
- Logs are written to `logs/mocra.{name}` by default and can be overridden via environment variables.

---

## 7. Development Guide

### 7.1 Dependencies and Environment

- Rust toolchain (stable recommended)
- Redis (local or container)
- Postgres (local or container)
- Optional: Kafka (for high-throughput queue scenarios)

### 7.2 Local Development Workflow

1. Prepare configuration: copy and modify test config
	- [tests/config.test.toml](tests/config.test.toml)
2. Initialize database (PG)
	- [init.sql](init.sql) and [seed_data.sql](seed_data.sql)
3. Start local Redis / Postgres
4. Run tests or benchmark programs (see 7.3)

### 7.3 Common Entrypoints

- Test runner: `tests_debug`
- Mock benchmark: `mock_benchmark`

> Entrypoints are defined in root [Cargo.toml](Cargo.toml).

### 7.4 Configuration and Hot Reload

The configuration system supports both file and Redis providers. Core definitions are in:
- [src/common/model/config.rs](src/common/model/config.rs)
- [src/common/state.rs](src/common/state.rs)

### 7.5 Logging

Logger initialization: `init_app_logger()`.
Related environment variables:
`DISABLE_LOGS` / `MOCRA_DISABLE_LOGS`.

More details:
- [docs/design/utils.md](docs/design/utils.md)

---

## 8. Advanced Topics and Optimization

For performance and optimization recommendations, see:
- `OPTIMIZATION.md`
- `docs/optimization.md`

---

## 9. Document Index (Retained)

New detailed implementation plans:
- `docs/design/task_model_chain_unification_plan.md`
- `docs/contract_test_coverage.md`
- `docs/alerts/backpressure_runbook.md`
- `docs/alerts/cas_fencing_runbook.md`
- `docs/dashboards/threshold_calibration_template.md`
- `docs/dashboards/baseline_report_template.md`
- `docs/design/gray_release_sop.md`
- `docs/design/rollback_drill_checklist.md`

Documents merged or kept for historical reference:
- `docs/System_Architecture_zh.md`
- `docs/Design_Distributed_Cron.md`
- `docs/design/*`
- `docs/Optimization_*.md`
